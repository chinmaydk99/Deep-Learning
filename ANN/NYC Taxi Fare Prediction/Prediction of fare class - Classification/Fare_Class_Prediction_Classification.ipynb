{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output layer =2\n",
    "use cross entropy loss\n",
    "use argmax to obtain predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('NYCTaxiFares.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0        40.730521         -73.975499         40.744746                1  \n",
       "1        40.740558         -73.974232         40.744114                1  \n",
       "2        40.751118         -73.960064         40.766235                2  \n",
       "3        40.756422         -73.971205         40.748192                1  \n",
       "4        40.734202         -73.905956         40.743115                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the distance using haversine formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "   \n",
    "    r = 6371  # average radius of Earth in kilometers\n",
    "       \n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    \n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "     \n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = (r * c) # in kilometers\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dist_km'] = haversine_distance(df,'pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km  \n",
       "0  2.126312  \n",
       "1  1.392307  \n",
       "2  3.326763  \n",
       "3  1.864129  \n",
       "4  7.231321  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the timestamp data and obtaining categorical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_datetime', 'fare_amount', 'fare_class', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count', 'dist_km'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EDTDate'] = df['pickup_datetime'] - pd.Timedelta(hours=4)\n",
    "df['Hour'] = df['EDTDate'].dt.hour\n",
    "df['AMorPM'] = np.where(df['Hour'] > 12 , 'pm','am')\n",
    "df['Weekday'] = df['EDTDate'].dt.strftime(\"%a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the categorical, continuous and output columns. Categorize the categorical ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Hour','AMorPM','Weekday']\n",
    "cont_cols = ['pickup_longitude','pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','passenger_count', 'dist_km']\n",
    "y_col = ['fare_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = df['Hour'].cat.codes.values\n",
    "ampm = df['AMorPM'].cat.codes.values\n",
    "weekday = df['Weekday'].cat.codes.values\n",
    "\n",
    "cats = np.stack([hr,ampm,weekday],1)\n",
    "cats = torch.tensor(cats, dtype = torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conts = np.stack([df[col].values for col in cont_cols],axis=1)\n",
    "conts = torch.tensor(conts,dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!!! Important for cross-entropy\n",
    "Note: the CrossEntropyLoss function we'll use below expects a 1d y-tensor, so we'll replace <tt>.reshape(-1,1)</tt> with <tt>.flatten()</tt> this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flatten() returns the copy of the input array in 1 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(df[y_col].values).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1,  ..., 1, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_szs = [len(df[col].cat.categories) for col in cat_cols]\n",
    "emb_szs = [(size,min(50,(size+1)//2)) for size in cat_szs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self,emb_szs,n_cont,out_size,layers,p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni,nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.batch_norm = nn.BatchNorm1d(n_cont)\n",
    "\n",
    "        layer_list = []\n",
    "        n_emb = sum([nf for ni,nf in emb_szs])\n",
    "        n_in = n_cont + n_emb\n",
    "\n",
    "        for i in layers:\n",
    "            layer_list.append(nn.Linear(n_in,i))\n",
    "            layer_list.append(nn.ReLU(inplace=True))\n",
    "            layer_list.append(nn.BatchNorm1d(i))\n",
    "            layer_list.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        \n",
    "        layer_list.append(nn.Linear(layers[-1],out_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*layer_list)\n",
    "\n",
    "    def forward(self,x_cat,x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings,1)\n",
    "        x = self.emb_drop(x)\n",
    "\n",
    "        x_cont = self.batch_norm(x_cont)\n",
    "        x = torch.cat([x,x_cont],1)\n",
    "        x = self.layers(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(33)\n",
    "model = TabularModel(emb_szs,conts.shape[1],2,[200,100],p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.5, inplace=False)\n",
       "  (batch_norm): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr =0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60000\n",
    "test_size = int(batch_size * .2)\n",
    "\n",
    "cat_train = cats[:batch_size-test_size]\n",
    "cat_test = cats[batch_size-test_size:batch_size]\n",
    "con_train = conts[:batch_size-test_size]\n",
    "con_test = conts[batch_size-test_size:batch_size]\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10 loss:0.6232612729072571\n",
      "Epoch:20 loss:0.6469186544418335\n",
      "Epoch:30 loss:0.5338454842567444\n",
      "Epoch:40 loss:0.3075760304927826\n",
      "Epoch:50 loss:0.292965292930603\n",
      "Epoch:60 loss:0.27715882658958435\n",
      "Epoch:70 loss:0.27080610394477844\n",
      "Epoch:80 loss:0.26865383982658386\n",
      "Epoch:90 loss:0.2671998143196106\n",
      "Epoch:100 loss:0.2663172483444214\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "epochs = 100\n",
    "\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    y_pred = model(cat_train,con_train)\n",
    "    loss = criterion(y_pred,y_train)\n",
    "    losses.append(loss.item())\n",
    "    if i%10 == 0:\n",
    "        print(f'Epoch:{i} loss:{loss.item()}')\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f54ced5150>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs),losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.25839176774024963\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model(cat_test,con_test)\n",
    "    loss = criterion(y_pred,y_test)\n",
    "\n",
    "print(f'Training loss:{loss}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the first 50 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([ 3.1060, -1.6553]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([-2.3864,  1.6021]) Predicted class:1 Actual Class:0\n",
      "Prediction: tensor([ 1.6926, -0.7461]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([-1.5612,  1.4260]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([ 2.7836, -1.4214]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([ 2.3990, -1.2171]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([ 2.7711, -1.4425]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([-2.3119,  1.5563]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([ 2.6438, -1.3590]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([-0.6992,  0.8467]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([ 2.3256, -1.1679]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([ 2.2319, -1.0643]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([ 1.8216, -0.7932]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([-1.4063,  1.3231]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([ 2.4582, -1.2512]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([-3.6453,  1.8310]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([ 3.0850, -1.6425]) Predicted class:0 Actual Class:1\n",
      "Prediction: tensor([ 2.7306, -1.4163]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([0.4988, 0.0696]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([ 2.1210, -1.0173]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([-1.1763,  1.1895]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([-0.4339,  0.6545]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([-2.0184,  1.5597]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([-1.9387,  1.4524]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([-4.4654,  1.8528]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([ 2.3096, -1.1428]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([ 2.4767, -1.2451]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([ 1.8475, -0.8310]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([-1.7380,  1.5086]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([ 2.0561, -0.9592]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([ 2.6753, -1.3661]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([-3.7426,  1.7507]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([-1.6730,  1.4734]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([-1.3515,  1.2951]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([ 2.3143, -1.1842]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([ 1.6246, -0.6894]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([-2.3860,  1.5642]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([ 1.9840, -0.9216]) Predicted class:0 Actual Class:1\n",
      "Prediction: tensor([ 0.9990, -0.2871]) Predicted class:0 Actual Class:1\n",
      "Prediction: tensor([ 2.9468, -1.5800]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([ 0.8053, -0.1214]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([ 0.8877, -0.1999]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([-0.8627,  0.9632]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([ 2.5664, -1.3102]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([ 0.6984, -0.0774]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([-1.0903,  1.0822]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([-3.0436,  1.6802]) Predicted class:1 Actual Class:1\n",
      "Prediction: tensor([ 2.9914, -1.5527]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([ 1.9033, -0.8803]) Predicted class:0 Actual Class:0\n",
      "Prediction: tensor([-0.1121,  0.4697]) Predicted class:1 Actual Class:0\n",
      "Out of 50 data points 45 correct predictions were obtained\n"
     ]
    }
   ],
   "source": [
    "rows = 50\n",
    "correct = 0\n",
    "\n",
    "for i in range(rows):\n",
    "    print(f'Prediction: {y_pred[i]} Predicted class:{y_pred[i].argmax()} Actual Class:{y_test[i]}')\n",
    "\n",
    "    if y_pred[i].argmax() == y_test[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(f'Out of {rows} data points {correct} correct predictions were obtained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to save the model only after the training has happened!\n",
    "if len(losses) == epochs:\n",
    "    torch.save(model.state_dict(), 'TaxiFareClssModel.pt')\n",
    "else:\n",
    "    print('Model has not been trained. Consider loading a trained model instead.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining Single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(mdl): # pass in the name of the new model\n",
    "    # INPUT NEW DATA\n",
    "    plat = float(input('What is the pickup latitude?  '))\n",
    "    plong = float(input('What is the pickup longitude? '))\n",
    "    dlat = float(input('What is the dropoff latitude?  '))\n",
    "    dlong = float(input('What is the dropoff longitude? '))\n",
    "    psngr = int(input('How many passengers? '))\n",
    "    dt = input('What is the pickup date and time?\\nFormat as YYYY-MM-DD HH:MM:SS     ')\n",
    "    \n",
    "    # PREPROCESS THE DATA\n",
    "    dfx_dict = {'pickup_latitude':plat,'pickup_longitude':plong,'dropoff_latitude':dlat,\n",
    "         'dropoff_longitude':dlong,'passenger_count':psngr,'EDTdate':dt}\n",
    "    dfx = pd.DataFrame(dfx_dict, index=[0])\n",
    "    dfx['dist_km'] = haversine_distance(dfx,'pickup_latitude', 'pickup_longitude',\n",
    "                                        'dropoff_latitude', 'dropoff_longitude')\n",
    "    dfx['EDTdate'] = pd.to_datetime(dfx['EDTdate'])\n",
    "    \n",
    "    # We can skip the .astype(category) step since our fields are small,\n",
    "    # and encode them right away\n",
    "    dfx['Hour'] = dfx['EDTdate'].dt.hour\n",
    "    dfx['AMorPM'] = np.where(dfx['Hour']<12,0,1) \n",
    "    dfx['Weekday'] = dfx['EDTdate'].dt.strftime(\"%a\")\n",
    "    dfx['Weekday'] = dfx['Weekday'].replace(['Fri','Mon','Sat','Sun','Thu','Tue','Wed'],\n",
    "                                            [0,1,2,3,4,5,6]).astype('int64')\n",
    "    # CREATE CAT AND CONT TENSORS\n",
    "    cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "    cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
    "                 'dropoff_longitude', 'passenger_count', 'dist_km']\n",
    "    xcats = np.stack([dfx[col].values for col in cat_cols], 1)\n",
    "    xcats = torch.tensor(xcats, dtype=torch.int64)\n",
    "    xconts = np.stack([dfx[col].values for col in cont_cols], 1)\n",
    "    xconts = torch.tensor(xconts, dtype=torch.float)\n",
    "    \n",
    "    # PASS NEW DATA THROUGH THE MODEL WITHOUT PERFORMING A BACKPROP\n",
    "    with torch.no_grad():\n",
    "        z = mdl(xcats, xconts).argmax().item()\n",
    "    print(f'\\nThe predicted fare class is {z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "854ad7b50770bedaf0cab730b1aaabb765566ea98036f134b639e260bede141e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
